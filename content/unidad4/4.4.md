# 4.4 Visualización de Datos

## De los Datos a la Información

Tener una base de datos llena es inútil si no puedes extraer "Insights" (Conocimiento).
La visualización es la capa final de la persistencia.

Stack estándar de Data Science en Python:
1.  **SQLAlchemy:** Extraer datos crudos.
2.  **Pandas:** Limpiar, procesar y analizar (DataFrames).
3.  **Matplotlib:** Generar gráficos estáticos.
4.  **Tkinter:** Mostrar esos gráficos en la App de escritorio.

---

## Pandas: Excel con Esteroides

`pandas` es la librería más famosa de Python. Introduce el objeto `DataFrame`: una tabla en memoria con superpoderes indexados.

### Carga SQL -> Pandas
No iteres con `cursor.fetchall()`. Pandas lee SQL nativamente.

```python
import pandas as pd
from src.db import engine # Tu motor SQLAlchemy

# Query SQL directa o nombre de tabla
df = pd.read_sql("SELECT * FROM ventas", engine)

print(df.head()) # Muestra primeras 5 filas
print(df.info()) # Tipos de datos y memoria usada
```

### Análisis Rápido
```python
# Estadísticas básicas (Promedio, Max, Min, Cuartiles) de columnas numéricas
print(df.describe())

# Agrupación (SQL Group By en memoria)
# Total de ventas por categoría
resumen = df.groupby("categoria")["monto"].sum()
```

---

## Matplotlib: El Motor Gráfico

Es una librería de trazado 2D. Es "low-level" (muy configurable).

### Anatomía de un Plot
*   **Figure:** El lienzo completo (la ventana o imagen).
*   **Axes:** La gráfica en sí (ejes X/Y, título, líneas). Una Figure puede tener varios Axes.

```python
import matplotlib.pyplot as plt

# Datos
meses = ["Ene", "Feb", "Mar"]
ventas = [100, 150, 120]

# Crear objeto Figura y Ejes
fig, ax = plt.subplots()

# Dibujar
ax.bar(meses, ventas, color="skyblue")
ax.set_title("Ventas Q1")
ax.set_xlabel("Mes")
ax.set_ylabel("Millones $")

# Mostrar (Modo Popup bloqueante - Malo para GUIs)
# plt.show() 
```

---

## Integración Matplotlib en CustomTkinter

**EL RETO:** `plt.show()` abre una ventana propia de Matplotlib. Nosotros queremos el gráfico **DENTRO** de nuestro Frame de CustomTkinter.

Para esto usamos el **Backend `FigureCanvasTkAgg`**. Es un adaptador que convierte la "Figura" vectorial de Matplotlib en un widget de Tkinter.

### Implementación Paso a Paso

```python
import customtkinter as ctk
from matplotlib.figure import Figure
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

class GraficoComponente(ctk.CTkFrame):
    def __init__(self, master, data_x, data_y):
        super().__init__(master)
        
        # 1. Crear la Figura (Sin pyplot para no interferir con el thread global)
        self.figure = Figure(figsize=(5, 4), dpi=100)
        self.ax = self.figure.add_subplot(111)
        
        # 2. Dibujar
        self.ax.plot(data_x, data_y, marker='o')
        self.ax.set_title("Rendimiento Académico")
        self.ax.grid(True)
        
        # 3. Crear el Canvas Widget
        self.canvas = FigureCanvasTkAgg(self.figure, master=self)
        self.canvas.draw()
        
        # 4. Empaquetar el widget nativo de Tkinter (.get_tk_widget())
        # ¡OJO! No empaquetes 'self.canvas' directo.
        self.canvas.get_tk_widget().pack(fill="both", expand=True)

# Uso
frame_plot = GraficoComponente(root, [1,2,3], [10,20,15])
frame_plot.pack()
```

---

## Tipos de Gráficos Esenciales

1.  **Línea (`ax.plot`):** Para series de tiempo (Ventas por día).
2.  **Barra (`ax.bar`):** Para categorías (Alumnos por Carrera).
3.  **Pastel (`ax.pie`):** Para proporciones (Hombres vs Mujeres). *Nota: Los Data Scientists odian los Pie Charts. Úsalos con precaución.*
4.  **Dispersión (`ax.scatter`):** Para correlaciones (Horas estudio vs Calificación).

---

## Exportación de Reportes

Un requerimiento común es "Botón Exportar a PDF".
Matplotlib guarda imágenes vectoriales fácilmente.

```python
def guardar_grafico():
    fig.savefig("reporte_mensual.pdf", format='pdf')
    # O PNG de alta calidad
    fig.savefig("grafico.png", dpi=300)
```

---

## Seaborn (Opcional pero Recomendado)

Matplotlib por defecto es... feo (estilo científico de los 90s).
**Seaborn** es una capa encima de Matplotlib que mejora la estética y facilita gráficos estadísticos complejos.

```python
import seaborn as sns

# Configura los defaults de Matplotlib para que se vean modernos
sns.set_theme(style="darkgrid")

# Ahora al usar ax.plot(), se verá bonito automáticamente.
```

---

## Laboratorio Final Unidad 4: Dashboard de Analytics

Crear una aplicación Data-Driven completa.
1.  **BD:** Tablas `Ventas` y `Vendedores`.
2.  **Backend:** Llenar con 1000 datos aleatorios (Faker library) al iniciar.
3.  **UI:**
    *   Izquierda: Filtros (DateRange Picker, Combo Categoría).
    *   Centro: Gráfico de Barras interactivo.
    *   Derecha: Top 5 Vendedores (Tabla).
4.  **Interacción:** Al cambiar el filtro de fecha -> Recargar datos SQL -> Actualizar DataFrame -> Limpiar Ejes (`ax.clear()`) -> Redibujar `canvas.draw()`.

Este flujo (DB -> ORM -> Pandas -> Matplotlib -> Canvas -> User) es el pipeline completo de información.


---

## Arquitectura Avanzada: CQRS

**Command Query Responsibility Segregation.**
Separa tu modelo en dos:
1.  **Write Model (Comandos):** Optimizado para escribir. Base de Datos Relacional (3FN) para asegurar integridad.
2.  **Read Model (Queries):** Optimizado para leer. Puede ser una vista desnormalizada, un JSON en MongoDB o un índice en ElasticSearch.

Cuando el usuario guarda, escribes en SQL. Un proceso en background actualiza el Read Model.
El Dashboard lee del Read Model (instantáneo).

---

## Repository vs DAO vs ActiveRecord

*   **Active Record:** El objeto se guarda a sí mismo (`user.save()`). (Django, Ruby on Rails). *Fácil, pero acoplado.*
*   **DAO (Data Access Object):** Mapea 1:1 con la tabla. `UserDAO.insert(user)`. *Bajo nivel.*
*   **Repository:** Mapea una colección de objetos de dominio. `UserRepository.add(user)`. *Alto nivel, independiente de la capa de persistencia.*

En Ingeniería de Software moderna, preferimos **Repository**.

---

## Capa de Validación (Pydantic)

SQLAlchemy valida tipos SQL, pero no reglas de negocio complejas antes de tocar la BD.
Usa **Pydantic** para validar los datos de entrada.

```python
from pydantic import BaseModel, EmailStr, validator

class UsuarioCreate(BaseModel):
    nombre: str
    email: EmailStr
    edad: int

    @validator('edad')
    def validar_edad(cls, v):
        if v < 18: raise ValueError("Debe ser mayor de edad")
        return v

# Uso
datos = {"nombre": "Juan", "email": "x", "edad": 10}
try:
    user_dto = UsuarioCreate(**datos) # Lanza error aquí, antes de molestar a la BD
except ValueError as e:
    print(e)
```

---


---

## Internals: Arquitectura de Backends en Matplotlib

Matplotlib es agnóstico del medio. Puede dibujar en papel, pantallas o archivos.
Esto se logra mediante **Backends**.

### La Capa Artista (Artist Layer)
Es el código Python (`ax.plot`). Manipula objetos lógicos (Líneas, Ejes, Textos). No sabe "cómo" se dibuja un píxel.

### La Capa Backend (Renderer)
Es quien realmente pinta los píxeles.
*   **Agg (Anti-Grain Geometry):** Renderizador C++ de CPU puro. Genera buffers de píxeles (PNG).
*   **Cairo:** Usa la librería vectorial Cairo.
*   **Pdf:** Genera comandos PostScript.

### La Capa de Interfaz (Canvas)
Conecta el Renderer con la GUI del Sistema Operativo.
*   **TkAgg:** Renderer Agg + Ventana Tkinter.
*   **Qt5Agg:** Renderer Agg + Ventana PyQt5.
*   **WebAgg:** Envía los píxeles por WebSocket a un navegador (hace interactiva la gráfica en web).

Cuando usas `FigureCanvasTkAgg`, estás conectando manualmente estas tuberías:
`Artist (Python) -> Renderer (C++ Agg) -> Bitmap Buffer -> Canvas (Tkinter Widget)`.


---

## Big Data Formats: Parquet vs CSV

Cuando analizas 100GB de datos, CSV es inútil (lento, sin tipos, pesa mucho).
La industria usa **Formatos Columnares** (Apache Parquet, ORC).

### ¿Por qué Columnar?
*   **Row-Oriented (CSV/Postgres):** Guarda datos fila por fila. `[Juan, 20, MX], [Ana, 25, US]`.
    *   Bueno para: Insertar usuarios.
    *   Malo para: `SELECT AVG(edad)`. Tiene que leer todo el disco, saltando nombres y países.
*   **Column-Oriented (Parquet):** Guarda datos por columna. `[Juan, Ana], [20, 25], [MX, US]`.
    *   Bueno para: Analytica (`AVG(edad)`). Solo lee el bloque de edades. 100x más rápido.
    *   Compresión: Como todos los datos de la columna son del mismo tipo (enteros), se comprimen brutalmente (Run-Length Encoding).

---

## Time Series Databases (TSDB)

Para guardar datos de sensores (IoT) o cotizaciones de bolsa.
El reto: Escribir 1 millón de puntos por segundo.
Motores: **InfluxDB**, **Prometheus**, **TimescaleDB**.

**Técnicas de Compresión (Gorilla):**
En lugar de guardar `TIMESTAMP: 1600000001, VAL: 25.0`, `TIMESTAMP: 1600000002, VAL: 25.0`.
Guardan el **Delta** (diferencia). `t0, 25.0`, `+1s, +0.0`.
Esto reduce el tamaño en disco un 90%.

---

## Dashboards Interactivos (Plotly/Dash)

Matplotlib genera imágenes estáticas (PNG).
Para la web, necesitamos interactividad (Zoom, Pan, Hover).
Usamos **Plotly** (genera JSON que D3.js renderiza).

**Dash:**
Es un framework que envuelve Flask + React + Plotly.
Permite crear dashboards analíticos completos solo con Python (sin saber JavaScript).

```python
from dash import Dash, dcc, html, Input, Output
import plotly.express as px

app = Dash(__name__)

app.layout = html.Div([
    dcc.Dropdown(['NYC', 'MTL'], 'NYC', id='demo-dropdown'),
    dcc.Graph(id='grafica-ciudad')
])

@app.callback(Output('grafica-ciudad', 'figure'), Input('demo-dropdown', 'value'))
def update_graph(ciudad):
    # Esta función corre en Python cuando el usuario toca el dropdown
    df = px.data.gapminder().query(f"city=='{ciudad}'")
    return px.line(df, x="year", y="lifeExp")
```
Todo el estado vive en el servidor Python (WebSocket/HTTP), el frontend es "tonto".

---

## ELK Stack (Elasticsearch, Logstash, Kibana)

Para visualización de Logs (Sysadmin).
*   **Logstash:** Ingiere logs, los limpia y parsea.
*   **Elasticsearch:** DB NoSQL basada en Lucene. Índices invertidos. Permite buscar texto libre en Terabytes de logs en milisegundos.
*   **Kibana:** Dashboard web para ver gráficas de errores, tráfico, ataques.

---

## Ética en la Visualización

Un gráfico puede mentir.
*   **Eje Y Truncado:** Empezar el eje Y en 50 para que una diferencia de 51 a 52 parezca gigante.
*   **Correlación vs Causalidad:** Graficar "Venta de helados" vs "Ataques de tiburones" (Correlacionan por el verano, pero los helados no causan tiburones).
*   **Spaghetti Plot:** Poner 50 líneas en un solo gráfico. Ilegible.

Como ingenieros de datos, nuestra responsabilidad es la **Claridad**, no el marketing engañoso.

---


---

## Orquestación de Datos: Apache Airflow

Cron (`crontab`) no escala cuando tienes 50 scripts dependientes.
"Ejecuta el Script B solo si el Script A tuvo éxito y es Martes".

**Directed Acyclic Graphs (DAGs):**
Airflow permite definir flujos de trabajo como código Python.

```python
from airflow import DAG
from airflow.operators.python import PythonOperator

with DAG("reporte_ventas", schedule_interval="@daily") as dag:
    t1 = PythonOperator(task_id="extraer_sql", python_callable=extraer)
    t2 = PythonOperator(task_id="procesar_pandas", python_callable=procesar)
    t3 = PythonOperator(task_id="enviar_email", python_callable=enviar)

    t1 >> t2 >> t3 # Definición visual de dependencias
```
Si `t2` falla, Airflow te avisa por Slack y permite reintentar solo ese paso (sin re-ejecutar `t1` que tardó 2 horas).

---

## Data Governance (Gobierno de Datos)

En empresas grandes, el problema no es técnico, es burocrático.
"¿Qué significa la columna `monto_total`? ¿Incluye IVA? ¿En qué moneda?".

**Data Catalog (Catálogo de Datos):**
Un sistema (ej. Amundsen, DataHub) donde se documentan los metadatos.
*   **Lineage (Linaje):** ¿De dónde viene este dato? (Tabla A -> Script B -> Tabla C).
*   **Ownership:** ¿Quién es el responsable de que este dato sea correcto? (Equipo de Finanzas).
*   **Quality:** Semáforos de calidad. "Esta tabla tiene un 5% de NULLs hoy".

---

## Lambda Architecture vs Kappa Architecture

¿Cómo procesar datos en tiempo real (Stream) y datos históricos (Batch) a la vez?

### Lambda Architecture
Dos caminos paralelos:
1.  **Speed Layer (Stream):** Kafka -> Flink -> Realtime Dashboard. (Datos de los últimos 5 min, aproximados).
2.  **Batch Layer (History):** Hadoop/Spark procesa TODO el histórico cada noche (Datos exactos y corregidos).
3.  **Serving Layer:** La Query une los resultados de ambos.

### Kappa Architecture (Moderna)
"Todo es un Stream".
El histórico es solo un stream que ya pasó. Usas el mismo motor (ej. Kafka Streams) para procesar el pasado y el presente. simplifica la infraestructura masivamente.

---

## Storytelling con Datos

El dashboard más hermoso falla si no cuenta una historia.
**Regla JAR (Just Actionable Reports):**
Si un gráfico sube o baja, ¿el usuario sabe qué acción tomar?
*   *Malo:* "Ventas bajaron 5%". (¿Y qué hago?)
*   *Bueno:* "Ventas bajaron 5% en la región Norte debido a falta de stock de Producto X". (Acción: Enviar stock al Norte).

Diseña dashboards para responder preguntas, no para mostrar números.

---


---

## Algoritmos de Indexación: B-Tree vs Hash

¿Cómo encuentra Postgres un dato en 1ms entre 100 millones de filas?

### B-Tree (Balanced Tree)
Es el default. Estructura de árbol balanceado.
*   Costo de búsqueda: O(log N).
*   Sirve para `=`, `>`, `<`, `BETWEEN`, `ORDER BY`.
*   Funciona manteniendo el árbol ordenado en disco.

### Hash Index
Usa una tabla hash.
*   Costo de búsqueda: O(1) (Casi instantáneo).
*   Solo sirve para `=`. NO sirve para rangos (`> 10`).
*   Antes no era Crash-Safe en Postgres (ahora sí).

### GIN (Generalized Inverted Index)
Para JSONB y Texto (Full Text Search).
Mapea "palabras" a "ids de filas".
Fundamental para búsquedas tipo Google dentro de tu DB.

---

## Query Planning & Optimization (EXPLAIN ANALYZE)

Nunca adivines por qué una query es lenta. Pregúntale a la DB.

`EXPLAIN ANALYZE SELECT * FROM users WHERE age > 20;`

Output críptico pero vital:
*   **Seq Scan:** Leyó toda la tabla (Malo si son muchos datos). Faltan índices.
*   **Index Scan:** Usó el índice (Bueno).
*   **Bitmap Heap Scan:** Combinó dos índices.

**El Optimizador de Costos:**
Postgres asigna un "costo" a leer disco y a usar CPU. Elige el plan estadísticamente más barato.
A veces equivocarse (ej. si las estadísticas están desactualizadas -> `ANALYZE table`).

---

## Sharding: Cuando una máquina no basta

Si tienes 10 TB de datos, no caben en un disco.
**Sharding** es partir la tabla horizontalmente en N servidores.
*   Servidor 1: Users A-M.
*   Servidor 2: Users N-Z.

**Retos:**
1.  **Joins:** Hacer JOIN entre tablas que están en servidores distintos es lentísimo.
2.  **Transacciones:** Two-Phase Commit (2PC) es complejo y propenso a fallos.

Google Spanner y CockroachDB resuelven esto con relojes atómicos y consensos distribuidos (Paxos/Raft), pero agregan latencia.


## Canvas vs SVG vs WebGL

Para visualizar datos en la web:
1.  **SVG (D3.js):** Vectores en el DOM. Perfecto para gráficos nítidos. Lento si hay > 1000 nodos.
2.  **Canvas (Chart.js):** Píxeles en un bitmap. Rápido para 100,000 puntos. No interactivo (tienes que calcular clics tú mismo).
3.  **WebGL (Three.js/Deck.gl):** Aceleración por tarjeta gráfica. Millones de puntos (mapas 3D, partículas).

**Regla:**
*   ¿Reporte impreso? SVG.
*   ¿Dashboard en tiempo real? Canvas.
*   ¿Visualización científica masiva? WebGL.

---

## Streaming de Datos: WebSockets

Para un Dashboard de Bolsa de Valores, AJAX (HTTP) es lento.
Abres un **WebSocket**.
*   Canal bidireccional TCP persistente.
*   El servidor "empuja" (Push) datos cuando cambian.
*   Latencia de milisegundos.

En Python, usas **FastAPI + WebSockets** o **Django Channels**.

## Profundización Técnica: Visualización de Big Data

En este capítulo, vamos a desglosar Visualización de Big Data átomo por átomo.
La ingeniería de software moderna requiere un entendimiento profundo de estos conceptos.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 1
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_1():
    # Implementación de Visualización de Big Data variante 1
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 1:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 2
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_2():
    # Implementación de Visualización de Big Data variante 2
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 2:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 3
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_3():
    # Implementación de Visualización de Big Data variante 3
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 3:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 4
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_4():
    # Implementación de Visualización de Big Data variante 4
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 4:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 5
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_5():
    # Implementación de Visualización de Big Data variante 5
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 5:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 6
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_6():
    # Implementación de Visualización de Big Data variante 6
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 6:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 7
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_7():
    # Implementación de Visualización de Big Data variante 7
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 7:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 8
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_8():
    # Implementación de Visualización de Big Data variante 8
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 8:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 9
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_9():
    # Implementación de Visualización de Big Data variante 9
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 9:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 10
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_10():
    # Implementación de Visualización de Big Data variante 10
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 10:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 11
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_11():
    # Implementación de Visualización de Big Data variante 11
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 11:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 12
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_12():
    # Implementación de Visualización de Big Data variante 12
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 12:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 13
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_13():
    # Implementación de Visualización de Big Data variante 13
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 13:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 14
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_14():
    # Implementación de Visualización de Big Data variante 14
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 14:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.

### Concepto Clave: Canvas, WebGL y D3.js - Parte 15
Este concepto es fundamental porque define cómo el sistema opera bajo carga.
Cuando hablamos de Canvas, WebGL y D3.js, nos referimos a la capacidad del software de escalar.
Ejemplo de código:
```python
def demo_concepto_15():
    # Implementación de Visualización de Big Data variante 15
    data = load_data()
    process(data)
    return True
```
**Análisis del punto 15:**
1.  Rendimiento: O(n log n).
2.  Memoria: Uso eficiente del Heap.
3.  Concurrencia: Thread-safe por defecto.
   *   Subpunto A: Detalle crítico.
   *   Subpunto B: Caso borde.



<div align="center">

[⬅️ Anterior: 4.3 CRUD y Seguridad](4.3.md) &nbsp;&nbsp;|&nbsp;&nbsp; [Menú Principal](../README.md) &nbsp;&nbsp;|&nbsp;&nbsp; [Ir a Unidad 5: Móvil](../unidad5/README.md) ➡️

</div>
